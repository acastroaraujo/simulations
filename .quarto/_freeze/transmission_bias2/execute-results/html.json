{
  "hash": "c85ea6b9e5a54f9bd49391da8c3d4c56",
  "result": {
    "markdown": "# Biased Transmission 2 {#sec-biased-transmission-indirect}\n\n**This notebook looks at *demonstrator-based copying,* often called \"indirect\" or \"context\" bias. This is also often called *cultural selection.***\n\n*Note. All quotations come from [here](https://bookdown.org/amesoudi/ABMtutorial_bookdown/model4.html).*\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Set up and helper functions\"}\nlibrary(tidyverse)\nlibrary(future.apply)\ntheme_set(theme_light(base_family = \"Amiri\"))\n\n# helper functions\n\nrerun_parallel <- function(S, f, ...) {\n  stopifnot(is.function(f))\n  params <- list(...)\n  \n  ## parallel runs\n  require(future.apply)\n  future::plan(multisession, workers = parallel::detectCores() - 1L)\n  sim <- future_replicate(S, do.call(f, params))\n  colnames(sim) <- paste0(\"run\", 1:S)\n  \n  ## data processing\n  output <- tibble::as_tibble(sim) |> \n    tibble::rowid_to_column(\"generation\") \n  \n  ## adds attributes to output\n  structure(output, params = params, model = deparse(substitute(f)))\n}\n\nplotSimulation <- function(rerun_out) {\n  \n  params <- unlist(attr(rerun_out, \"params\"))\n  param_labels <- paste(paste(names(params), params, sep = \"=\"), collapse = \",   \")\n  \n  avg <- rowMeans(dplyr::select(rerun_out, !generation))\n  \n  rerun_out |> \n    tidyr::pivot_longer(!generation, names_to = \"simulation\", values_to = \"p\") |> \n    ggplot2::ggplot(aes(generation, p)) + \n    ggplot2::geom_line(alpha = 1/10, aes(group = simulation)) + \n    ggplot2::ylim(0, 1) + \n    ggplot2::geom_line( ## average\n      data = tibble::tibble(generation = 1:params[[\"t_max\"]], p = avg), \n      color = \"pink\"\n    ) + \n    ggplot2::labs(caption = param_labels, title = attr(rerun_out, \"model\"))\n}\n```\n:::\n\n\nIn this model, certain demonstrators are more likely to be copied than other demonstrators.\n\n> Indirect bias comes in several forms. Learners might preferentially copy demonstrators who have high success or payoffs (which may or may not derive from their cultural traits), demonstrators who are old (and perhaps have accrued valuable knowledge, or at least good enough to keep them alive to old age), demonstrators who are the same gender as the learner (if cultural traits are gender-specific), or demonstrators who possess high social status or prestige.\n\n## Payoff Bias\n\nIn this model, new agents preferentially copy the traits of those agents in the previous generation who exhibit higher relative payoffs. This is sometimes called \"payoff\" or \"success\" bias.\n\nThe main difference between this model and the one in @sec-biased-transmission-direct is that demonstrator choice is no longer random; demonstrators are chosen based on their payoffs. Thus, we need to implement payoffs for each agent.\n\n> We will assume that an agent's payoff is determined solely by the agent's cultural trait. Agents with trait $B$ have payoff of $1$ (a \"baseline\" payoff), while agents with trait $A$ have payoff of $1+s$. This means that trait $A$ gives a payoff advantage to its bearers, relative to agents possessing trait $B$. The larger is $s$, the bigger this relative advantage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIndirectBias <- function(\n    N,     # number of agents,\n    s,     # relative advantage,\n    p_0,   # initial proportion of trait \"A\",\n    t_max  # number of generations\n  ) {\n  \n  agent <- data.frame(\n    trait = sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0))\n  ) \n\n  agent$payoff[agent$trait == \"A\"] <- 1 + s\n  agent$payoff[agent$trait == \"B\"] <- 1\n  \n  agent_list <- purrr::accumulate(\n    .x = 2:t_max, \n    .init = agent, \n    .f = function(agent, ...) {\n      \n      previous_agent <- agent ## copy agent to previous_agent dataframe\n      relative_payoffs <- agent$payoff / sum(agent$payoff) ## get relative payoffs\n      \n      agent$trait <- sample(\n        x = previous_agent$trait, \n        size = N, \n        replace = TRUE, \n        prob = relative_payoffs\n      )\n      \n      ## add payoffs\n      agent$payoff[agent$trait == \"A\"] <- 1 + s\n      agent$payoff[agent$trait == \"B\"] <- 1\n \n      return(agent)\n  })\n  \n  p <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait == \"A\") / N)\n  return(p)\n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nout <- rerun_parallel(S = 300, IndirectBias, N = 10000, s = 0.1, p_0 = 0.01, t_max = 150)\nplotSimulation(out)\n```\n\n::: {.cell-output-display}\n![](transmission_bias2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nThis S-shaped curve is very similar to the one generated in @sec-biased-transmission-direct for *direct bias.* This shouldn't be surprising given that \"an agent's payoff is entirely determined by their cultural trait. Under these assumptions, preferentially copying high payoff agents is functionally equivalent to preferentially copying high payoff traits.\"\n\nThis is not always the case.\n\n## Hitch-hiking\n\n> A more interesting case of indirect bias occurs when individuals possess two cultural traits, one functional and the other neutral. Under certain circumstances, payoff based indirect bias can cause the neutral trait to 'hitch-hike' alongside the functional trait. Neutral traits can spread in the population simply because they are associated with high payoff traits in high payoff demonstrators, even though they have no effect on payoffs themselves.\n\nIn the previous model, trait $A$ is **functional** in that it has a higher payoff than $B$ when $s \\gt 0$. A neutral trait, on the other hand, has no effect on payoffs, much like the traits in @sec-unbiased-transmission (unbiased transmission).\n\nHere, we will add a second neutral trait to `IndirectBias()`, which we label $X$ or $Y$. We also define $q$ as the proportion of $X$ in trait 2.\n\n> We will model a situation where the two traits may be initially linked. We are not going to be concerned here with why the two traits are initially linked. The link could, for example, have arisen by chance due to drift in historically small populations. We will leave this as an assumption of our model, which is fine as long as we are explicit about this.\n\n$L$ specifies the probability that, in the starting generation, if an individual has $A$ for trait 1 it also has $X$ for trait 2. When $L = 1$, there is a maximum linkage between the two traits---i.e., all individuals with $A$ also have $X$. As $L$ gets smaller, this linkage breaks.\n\nIn sum, the demonstrators are picked as before (based on relative payoffs), except that trait 2 is copied from the same demonstrator alongside trait 1.\n\n*Note. There's also a new parameter* $q_0$ *which looks a lot like* $p_0$ *but is conditional on* $L$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIndirectBias2 <- function(\n    N,     # number of agents,\n    s,     # relative advantage,\n    L,     # probability that specifies linkage between \"A\" and \"X\",\n    p_0,   # initial proportion of trait \"A\",\n    q_0,   # initial proportion \n    t_max  # number of generations\n  ) {\n  \n  agent <- data.frame(\n    trait1 = sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0)),\n    trait2 = rep(NA_character_, N)\n  ) \n  \n  # with prob L, trait 2 is tied to trait 1\n  prob <- runif(N)\n  agent$trait2[agent$trait1 == \"A\" & prob < L] <- \"X\"\n  agent$trait2[agent$trait1 == \"B\" & prob < L] <- \"Y\"\n  \n  # otherwise trait \"X\" with prob q_0 (and \"Y\" with 1 - q_0)\n  agent$trait2[prob >= L] <- sample(\n    x = c(\"X\",\"Y\"), \n    size = sum(prob >= L), \n    replace = TRUE,\n    prob = c(q_0, 1-q_0)\n  )\n    \n  agent$payoff[agent$trait1 == \"A\"] <- 1 + s\n  agent$payoff[agent$trait1 == \"B\"] <- 1\n  \n  agent_list <- purrr::accumulate(\n    .x = 2:t_max, \n    .init = agent, \n    .f = function(agent, ...) {\n      \n      previous_agent <- agent ## copy agent to previous_agent dataframe\n      relative_payoffs <- agent$payoff / sum(agent$payoff) ## get relative payoffs\n      \n      # new traits copied from previous generation, biased by payoffs\n      demonstrators <- sample(1:N, size = N, replace = TRUE, prob = relative_payoffs)\n      \n      agent$trait1 <- previous_agent$trait1[demonstrators]\n      agent$trait2 <- previous_agent$trait2[demonstrators]\n      \n      ## add payoffs\n      agent$payoff[agent$trait1 == \"A\"] <- 1 + s\n      agent$payoff[agent$trait1 == \"B\"] <- 1\n \n      return(agent)\n  })\n  \n  p <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait1 == \"A\") / N)\n  q <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait2 == \"X\") / N)\n  \n  data.frame(p, q)\n  \n}\n```\n:::\n\n\n<aside>\n\nThis presents a coding challenge since the previous helper functions expect the simulation to have 1 vector as an output, but this simulation outputs `p` and `q`.\n\n</aside>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout <- IndirectBias2(\n  N = 10000, \n  s = 0.1,\n  L = 0.9,\n  p_0 = 0.01,\n  q_0 = 0.5,\n  t_max = 150\n)\n\n\nout |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(!generation) |> \n  ggplot(aes(generation, value, color = name)) + \n  geom_line()\n```\n\n::: {.cell-output-display}\n![](transmission_bias2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nHOW DO I INTEGRATE THIS WITH THE HELPER FUNCTIONS??\n",
    "supporting": [
      "transmission_bias2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}