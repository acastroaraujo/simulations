[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulations",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nIt contains my experiments with computer simulations in R.\nI’ll start using some examples from this book, but eventually I’ll add more."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Some general remarks about models and agent-based modeling in particular."
  },
  {
    "objectID": "cultural_evolution.html",
    "href": "cultural_evolution.html",
    "title": "Cultural Evolution",
    "section": "",
    "text": "Some remarks"
  },
  {
    "objectID": "unbiased_transmission.html",
    "href": "unbiased_transmission.html",
    "title": "2  Unbiased Transmission",
    "section": "",
    "text": "Note. All quotations come from here."
  },
  {
    "objectID": "unbiased_transmission.html#introduction",
    "href": "unbiased_transmission.html#introduction",
    "title": "2  Unbiased Transmission",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nThis is perhaps the simplest possible model of cultural evolution.\n\nWe assume \\(N\\) individuals each of whom possesses one of two cultural traits, denoted \\(A\\) and \\(B\\). Each generation, the \\(N\\) agents are replaced with \\(N\\) new agents. Each new agent picks a member of the previous generation at random and copies their cultural trait. This is known as unbiased oblique cultural transmission: unbiased because traits are copied entirely at random, and oblique because one generation learns from the previous non-overlapping generation (as opposed to horizontal cultural transmission where individuals copy members of the same generation, and vertical cultural transmission where offspring copy their parents—our model is way too simple to have actual parents and offspring though).\n\nGiven this set up, what is the proportion \\(p\\) of individuals that have trait \\(A\\) over successive generations?\nFirst we specify the number of fixed parameters in the model.\n\n\\(N\\): the number of individuals\n\\(t_\\text{max}\\): the number of generations\n\n\nN <- 100\nt_max <- 200\n\nThen we create our agents, which we store in a vector.\n\nagent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE)\n\nstr(agent)\n\n chr [1:100] \"B\" \"A\" \"A\" \"B\" \"A\" \"B\" \"A\" \"A\" \"A\" \"B\" \"A\" \"B\" \"A\" \"A\" \"A\" ...\n\n\nWe also create a vector to track the trait frequency \\(p\\) in each generation.\n\np <- vector(\"double\", length = t_max)\n\nThe parameter \\(p\\) for the first generation is easy to calculate.\n\np[[1]] <- sum(agent == \"A\") / N\n\np[[1]]\n\n[1] 0.51\n\n\nWhat we want do next is iterate over \\(t_\\text{max}\\) generations.\n\nfor (t in 2:t_max) {\n  \n  # copy agent to previous_agent \n  previous_agent <- agent  \n  \n  # randomly copy from previous generation's agents\n  agent <- sample(previous_agent, N, replace = TRUE)\n  \n  # get p and put it into the output slot for this generation t\n  p[[t]] <- sum(agent == \"A\") / N\n  \n}\n\ntibble(p) |> \n  mutate(generation = row_number()) |> \n  ggplot(aes(generation, p)) + \n  geom_line() +\n  labs(title = str_glue(\"N = {N}\"))\n\n\n\n\n\nUnbiased transmission, or random copying, is by definition random, so different runs of this simulation will generate different plots. If you rerun all the code you’ll get something different again. […] This is a typical feature of cultural drift, analogous to genetic drift: in small populations, with no selection or other directional processes operating, traits can be lost purely by chance."
  },
  {
    "objectID": "unbiased_transmission.html#function",
    "href": "unbiased_transmission.html#function",
    "title": "2  Unbiased Transmission",
    "section": "2.2 Function",
    "text": "2.2 Function\n\nUnbiasedTransmission <- function(N, t_max) {\n  \n  agent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE)\n  p <- vector(\"double\", length = t_max)\n  p[[1]] <- sum(agent == \"A\") / N\n  \n  for (t in 2:t_max) {\n    previous_agent <- agent  \n    agent <- sample(previous_agent, N, replace = TRUE)\n    p[[t]] <- sum(agent == \"A\") / N\n  }\n  return(p)\n}\n\ntibble(p = UnbiasedTransmission(300, 500)) |> \n  mutate(generation = row_number()) |> \n  ggplot(aes(generation, p)) + \n  geom_line() +\n  labs(title = str_glue(\"N = 300\"))\n\n\n\n\nWe can run this function multiple times now.\n\nS <- 300 ## number of simulations\nG <- 200 ## number of generations\nN <- 100 ## number of individuals\n\nsim <- future_replicate(n = S, UnbiasedTransmission(N, G)) ## parallel replication\ncolnames(sim) <- paste0(\"run\", 1:S)\ndim(sim)\n\n[1] 200 300\n\ndf <- as_tibble(sim) |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(cols = !generation, names_to = \"simulation\", values_to = \"p\")\n\ndf |> \n  ggplot(aes(generation, p, group = simulation)) + \n  geom_line(alpha = 1/10)\n\n\n\n\nNote that \\(p\\) seems to go to either 0 or 1 over time. Let’s see what happens when we increase the number of generations.\n\nS <- 300 ## number of simulations\nG <- 1e3 ## number of generations\nN <- 100 ## number of individuals\n\nsim <- future_replicate(n = S, UnbiasedTransmission(N, G)) ## parallel replication\ncolnames(sim) <- paste0(\"run\", 1:S)\ndim(sim)\n\n[1] 1000  300\n\ndf <- as_tibble(sim) |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(cols = !generation, names_to = \"simulation\", values_to = \"p\")\n\ndf |> \n  ggplot(aes(generation, p, group = simulation)) + \n  geom_line(alpha = 1/10)\n\n\n\n\nNow we’ll run UnbiasedTransmission() with \\(N = 10,000\\).\n\nS <- 300  ## number of simulations\nG <- 1e3 ## number of generations\nN <- 10e3 ## number of individuals\n\nsim <- future_replicate(n = S, UnbiasedTransmission(N, G)) ## parallel replication\ncolnames(sim) <- paste0(\"run\", 1:S)\ndim(sim)\n\n[1] 1000  300\n\ndf <- as_tibble(sim) |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(cols = !generation, names_to = \"simulation\", values_to = \"p\")\n\ndf |> \n  ggplot(aes(generation, p, group = simulation)) + \n  geom_line(alpha = 1/5) + \n  ylim(0, 1)\n\n\n\n\nNote that with a large enough population, the proportion stays around 0.5. We can change the original proportion \\(p_0\\) and see if the results remain similar.\n\nUnbiasedTransmission <- function(N, t_max, p0) {\n  \n  agent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p0, 1-p0))\n  p <- vector(\"double\", length = t_max)\n  p[[1]] <- sum(agent == \"A\") / N\n  \n  for (t in 2:t_max) {\n    previous_agent <- agent  \n    agent <- sample(previous_agent, N, replace = TRUE)\n    p[[t]] <- sum(agent == \"A\") / N\n  }\n  return(p)\n}\n\nS <- 300    ## number of simulations\nG <- 200    ## number of generations\nN <- 10e3   ## number of individuals\np0 <- 0.16  ## initial proportion of trait \"A\"\n\nsim <- future_replicate(n = S, UnbiasedTransmission(N, G, p0)) \ncolnames(sim) <- paste0(\"run\", 1:S)\ndim(sim)\n\n[1] 200 300\n\ndf <- as_tibble(sim) |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(cols = !generation, names_to = \"simulation\", values_to = \"p\")\n\ndf |> \n  ggplot(aes(generation, p, group = simulation)) + \n  geom_line(alpha = 1/5) + \n  geom_hline(yintercept = p0, linetype = \"dashed\", color = \"red\") +\n  ylim(0, 1)\n\n\n\n\n\nUnbiased transmission is truly non-directional: it maintains trait frequencies at whatever they were in the previous generation, barring random fluctuations caused by small population sizes.\n[…]\nEven this extremely simple model provides some valuable insights. First, unbiased transmission does not in itself change trait frequencies. As long as populations are large, trait frequencies remain the same.\nSecond, the smaller the population size, the more likely traits are to be lost by chance. This is a basic insight from population genetics, known there as genetic drift, but it can also be applied to cultural evolution. More advanced models of cultural drift (sometimes called “random copying”) can be found in Cavalli-Sforza & Feldman (1981) and Bentley et al. (2004), with the latter showing that various real-world cultural traits exhibit dynamics consistent with this kind of process, including baby names, dog breeds and archaeological pottery types.\nFurthermore, generating expectations about cultural change under simple assumptions like random cultural drift can be useful for detecting non-random patterns like selection. If we don’t have a baseline, we won’t know selection or other directional processes when we see them."
  },
  {
    "objectID": "mutation.html",
    "href": "mutation.html",
    "title": "3  Mutation",
    "section": "",
    "text": "Note. All quotations come from here."
  },
  {
    "objectID": "mutation.html#unbiased-mutation",
    "href": "mutation.html#unbiased-mutation",
    "title": "3  Mutation",
    "section": "3.1 Unbiased Mutation",
    "text": "3.1 Unbiased Mutation\nThis model takes the same basic model as the one used in Chapter 2. We assume \\(N\\) individuals that possess one of two traits \\((A, B)\\) and a series of generations denoted by \\(t\\). But instead of random copying, each agent gives rise to a new agent with the same cultural trait as them.\nFor each generation there is a probability \\(\\mu\\) that each agent mutates from their current trait to the other trait. This probability applies to each agent independently. This means that, on average, \\(\\mu N\\) agents mutate each generation. Like in Chapter 2, we are interested in tracking the proportion of agents \\(p\\) with trait \\(A\\) over time.\nThis time I’ll create a series of helper functions from the start.\n\nUnbiasedMutation <- function(\n    N,      # number of agents,\n    mu,     # mutation probability,\n    p_0,    # initial proportion of trait \"A\"\n    t_max   # number of generations\n  ) {\n  \n  agent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0))\n  p <- vector(\"double\", length = t_max)\n  p[[1]] <- sum(agent == \"A\") / N\n  \n  for (t in 2:t_max) {\n    previous_agent <- agent  \n    \n    ## mutation\n    mutate <- runif(N)\n    \n    agent[previous_agent == \"A\" & mutate < mu] <- \"B\"\n    agent[previous_agent == \"B\" & mutate < mu] <- \"A\"\n    \n    p[[t]] <- sum(agent == \"A\") / N\n    \n  }\n  return(p)\n}\n\n## helper functions\n\nrerun_parallel <- function(S, f, ...) {\n  stopifnot(is.function(f))\n  params <- list(...)\n  \n  ## parallel runs\n  require(future.apply)\n  plan(multisession, workers = parallel::detectCores() - 1L)\n  sim <- future_replicate(S, do.call(f, params))\n  colnames(sim) <- paste0(\"run\", 1:S)\n  \n  ## data processing\n  output <- tibble::as_tibble(sim) |> \n    tibble::rowid_to_column(\"generation\") \n  \n  structure(output, params = params, model = deparse(substitute(f)))\n}\n\nplotSimulation <- function(rerun_out) {\n  \n  params <- unlist(attr(rerun_out, \"params\"))\n  param_labels <- paste(paste(names(params), params, sep = \"=\"), collapse = \"\\n\")\n  \n  avg <- rowMeans(rerun_out |> select(!generation))\n  \n  rerun_out |> \n    pivot_longer(!generation, names_to = \"simulation\", values_to = \"p\") |> \n    ggplot(aes(generation, p)) + \n    geom_line(alpha = 1/10, aes(group = simulation)) + \n    ylim(0, 1) + \n    geom_line( ## average\n      data = tibble(generation = 1:params[[\"t_max\"]], p = avg), \n      color = \"pink\"\n    ) + \n    labs(caption = param_labels, title = attr(rerun_out, \"model\"))\n  \n}\n\nThis is how we do it 🎵\n\nout <- rerun_parallel(S = 100, UnbiasedMutation, N = 100, mu = 0.05, t_max = 200, p_0 = 0.5) \nplotSimulation(out)\n\n\n\n\n\nAs one might expect, unbiased mutation produces random fluctuations over time, and does not alter the overall frequency of \\(A\\) which stays around \\(p=0.5\\). Because mutations from \\(A\\) to \\(B\\) are as equally likely as \\(B\\) to \\(A\\), there is no overall directional trend.\nBut what if we were to start at different initial frequencies of \\(A\\) and \\(B\\)? Say, \\(p=0.2\\) or \\(p=0.9\\)? Would unbiased mutation keep \\(p\\) at these initial values, like we saw unbiased transmission does in Chapter 2?\n\nThe answer is NO.\n\nout <- rerun_parallel(S = 100, UnbiasedMutation, N = 100, mu = 0.05, t_max = 200, p_0 = 0.1) \nplotSimulation(out)\n\n\n\nrerun_parallel(S = 100, UnbiasedMutation, N = 100, mu = 0.05, t_max = 200, p_0 = 0.99) |>\n  plotSimulation()\n\n\n\n\n\nUnbiased mutation always leads to \\(p=0.5\\).\n\nMATH EXPLAINER\nNow we’ll do the same simulation, but with three traits \\((A, B, C)\\).\n\nUnbiasedMutationThreeTraits <- function(\n    N,      # number of agents,\n    mu,     # mutation probability,\n    pA_0,   # initial proportion of trait \"A\"\n    pB_0,   # initial proportion of trait \"B\"\n    t_max   # number of generations\n  ) {\n  \n  agent <- sample(\n    x = c(\"A\", \"B\", \"C\"), \n    size = N, \n    replace = TRUE, \n    prob = c(pA_0, pB_0, 1-pA_0-pB_0)\n  )\n  \n  p <- vector(\"double\", length = t_max)\n  p[[1]] <- sum(agent == \"A\") / N\n  \n  for (t in 2:t_max) {\n    previous_agent <- agent  \n    \n    ## mutation\n    mutate <- runif(N)\n    \n    agent[previous_agent == \"A\" & mutate < mu] <- sample(c(\"B\", \"C\"), size = 1)\n    agent[previous_agent == \"B\" & mutate < mu] <- sample(c(\"A\", \"C\"), size = 1)\n    agent[previous_agent == \"C\" & mutate < mu] <- sample(c(\"A\", \"B\"), size = 1)\n    \n    p[[t]] <- sum(agent == \"A\") / N\n    \n  }\n  return(p)\n}\n\nDoes \\(p\\) still converge on 0.5, as it does with only two traits?\n\nout <- rerun_parallel(\n  S = 100, \n  f = UnbiasedMutationThreeTraits, \n  N = 100,\n  mu = 0.05,   \n  pA_0 = 0.9, \n  pB_0 = 0.05, \n  t_max = 200\n)\n\nplotSimulation(out)\n\n\n\n\nNo, it converges to \\(\\frac{1}{3}\\)."
  },
  {
    "objectID": "mutation.html#biased-mutation",
    "href": "mutation.html#biased-mutation",
    "title": "3  Mutation",
    "section": "3.2 Biased Mutation",
    "text": "3.2 Biased Mutation\n\nLet’s assume now that there is a probability \\(\\mu_b\\) that an agent with trait \\(B\\) mutates into \\(A\\), but there is no possibility of trait \\(A\\) mutating into trait \\(B\\). Perhaps trait \\(A\\) is a particularly catchy or memorable version of a story, or an intuitive explanation of a phenomenon, and \\(B\\) is difficult to remember or unintuitive.\nThe function BiasedMutation() captures this unidirectional mutation.\n\n\nBiasedMutation <- function(\n    N,    # number of agents,\n    mu_b, # mutation probability,\n    p_0,  # initial proportion of trait \"A\"\n    t_max # number of generations\n  ) {\n  \n  agent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0))\n  p <- vector(\"double\", length = t_max)\n  p[[1]] <- sum(agent == \"A\") / N\n  \n  for (t in 2:t_max) {\n    previous_agent <- agent  \n    \n    ## mutation\n    mutate <- runif(N)\n    \n    # taking this line out makes introduces the bias:\n    #agent[previous_agent == \"A\" & mutate < mu_b] <- \"B\" \n    agent[previous_agent == \"B\" & mutate < mu_b] <- \"A\"\n    \n    p[[t]] <- sum(agent == \"A\") / N\n    \n  }\n  return(p)\n  \n}\n\nTo see the effects of biased mutation, we’ll start with a population with all \\(B\\) traits.\n\nout <- rerun_parallel(100, BiasedMutation, N = 100, mu_b = 0.05, p_0 = 0, t_max = 200)\nplotSimulation(out)\n\n\n\n\nWe can try this same thing with different parameters for \\(N\\) and \\(\\mu_b\\).\n\nout <- rerun_parallel(100, BiasedMutation, N = 10e3, mu_b = 0.05, p_0 = 0, t_max = 200)\nplotSimulation(out)\n\n\n\n\n\nout <- rerun_parallel(100, BiasedMutation, N = 100, mu_b = 0.2, p_0 = 0, t_max = 200)\nplotSimulation(out)\n\n\n\n\n\nIn terms of programming techniques, the major novelty in [this Chapter] is the use of runif to generate a series of \\(N\\) random numbers from 0 to 1 and compare these to a fixed probability (in our case, \\(\\mu\\) or \\(\\mu_b\\)) to determine which agents should undergo whatever the fixed probability specifies (in our case, mutation). This could be done with a loop, but vectorising code in the way we did here is much faster in R than loops."
  },
  {
    "objectID": "transmission_bias1.html",
    "href": "transmission_bias1.html",
    "title": "4  Biased Transmission 1",
    "section": "",
    "text": "Note. All quotations come from here.\nIn this notebook I also replace loops entirely with functional programming.\n\nlibrary(tidyverse)\ntheme_set(theme_light(base_family = \"Amiri\"))\n\nlibrary(future.apply)\nplan(multisession, workers = parallel::detectCores() - 1L)\n\nAs in Chapter 2 and Chapter 3, we assume two traits \\((A, B)\\). Let’s further assume that biased transmission favors \\(A\\) (perhaps it’s “a more effective tool, more memorable story, or more easily pronounced word”).\n\nWe’re not including any mutation in the model, so we need to include some \\(A\\)s at the beginning of the simulation otherwise it would never appear. However, let’s make it initially rare. Then we can see how selection favors this initially-rare trait.\n\nFor each \\(t\\), each agent choose another agent from the previous generation at random. If that chosen agent has \\(A\\), then the focal agent copies \\(A\\) with probability \\(s\\).\n\nBiasedTransmission <- function(\n    N,     # number of agents,\n    s,     # transmission probability,\n    p_0,   # initial proportion of trait \"A\"\n    t_max  # number of generations\n  ) {\n  \n  agent <- sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0))\n  \n  agent_list <- purrr::accumulate(\n    .x = 2:t_max, ## this sequence gets discarded with the ... in the function call\n    .init = agent, \n    .f = function(agent, ...) {\n      \n      previous_agent <- agent\n      # for each agent, pick a random agent from the previous generation\n      # as demonstrator and store their trait\n      demonstrator_trait <- sample(previous_agent, N, replace = TRUE)\n      # get N random numbers each between 0 and 1\n      copy <- runif(N)\n      # if demonstrator has A and with probability s, copy A from demonstrator\n      agent[demonstrator_trait == \"A\" & copy < s] <- \"A\" \n      return(agent)\n  })\n  \n  p <- purrr::map_dbl(agent_list, function(agent) sum(agent == \"A\") / N)\n  return(p)\n}\n\nWe also use the same helper functions used in Chapter 3: rerun_parallel and plotSimulation.\n\n\nCode\nrerun_parallel <- function(S, f, ...) {\n  stopifnot(is.function(f))\n  params <- list(...)\n  \n  ## parallel runs\n  require(future.apply)\n  plan(multisession, workers = parallel::detectCores() - 1L)\n  sim <- future_replicate(S, do.call(f, params))\n  colnames(sim) <- paste0(\"run\", 1:S)\n  \n  ## data processing\n  output <- tibble::as_tibble(sim) |> \n    tibble::rowid_to_column(\"generation\") \n  \n  ## adds attributes to output\n  structure(output, params = params, model = deparse(substitute(f)))\n}\n\nplotSimulation <- function(rerun_out) {\n  \n  params <- unlist(attr(rerun_out, \"params\"))\n  param_labels <- paste(paste(names(params), params, sep = \"=\"), collapse = \",   \")\n  \n  avg <- rowMeans(rerun_out |> select(!generation))\n  \n  rerun_out |> \n    pivot_longer(!generation, names_to = \"simulation\", values_to = \"p\") |> \n    ggplot(aes(generation, p)) + \n    geom_line(alpha = 1/10, aes(group = simulation)) + \n    ylim(0, 1) + \n    geom_line( ## average\n      data = tibble(generation = 1:params[[\"t_max\"]], p = avg), \n      color = \"pink\"\n    ) + \n    labs(caption = param_labels, title = attr(rerun_out, \"model\"))\n}\n\n\nHere, we’ll start with a population that has a small number of trait \\(A\\). We will do \\(p_0 = 0.01\\).\n\nout <- rerun_parallel(S = 100, BiasedTransmission, N = 10000, s = 0.1, p_0 = 0.01, t_max = 150)\nplotSimulation(out)\n\n\n\n\nLet’s increase the strength of selection, \\(s = 0.2\\).\n\nout <- rerun_parallel(S = 100, BiasedTransmission, N = 10000, s = 0.2, p_0 = 0.01, t_max = 150)\nplotSimulation(out)\n\n\n\n\nMATH EXPLAINER\nNote. Henrich (2001) links s-shaped diffusion curves to this form of biased cultural transmission.\n\nExercise\n\nChange ss in BiasedTransmission to sasa, and add a new parameter sbsb which specifies the probability of an agent copying trait BB from a demonstrator who possesses that trait. Run the simulation to show that the equilibrium value of pp, and the speed at which this equilibrium is reached, depends on the difference between sasa and sbsb. How do these dynamics differ from the muamua and mubmub you implemented in Model 2 Q5?\n\n\n\n\n\nHenrich, Joseph. 2001. “Cultural Transmission and the Diffusion of Innovations: Adoption Dynamics Indicate That Biased Cultural Transmission Is the Predominate Force in Behavioral Change.” American Anthropologist 103 (4): 9921013."
  },
  {
    "objectID": "transmission_bias2.html",
    "href": "transmission_bias2.html",
    "title": "5  Biased Transmission 2",
    "section": "",
    "text": "This notebook looks at demonstrator-based copying, often called “indirect” or “context” bias. This is also often called cultural selection.\nNote. All quotations come from here.\nIn this model, certain demonstrators are more likely to be copied than other demonstrators."
  },
  {
    "objectID": "transmission_bias2.html#payoff-bias",
    "href": "transmission_bias2.html#payoff-bias",
    "title": "5  Biased Transmission 2",
    "section": "5.1 Payoff Bias",
    "text": "5.1 Payoff Bias\nIn this model, new agents preferentially copy the traits of those agents in the previous generation who exhibit higher relative payoffs. This is sometimes called “payoff” or “success” bias.\nThe main difference between this model and the one in Chapter 4 is that demonstrator choice is no longer random; demonstrators are chosen based on their payoffs. Thus, we need to implement payoffs for each agent.\n\nWe will assume that an agent’s payoff is determined solely by the agent’s cultural trait. Agents with trait \\(B\\) have payoff of \\(1\\) (a “baseline” payoff), while agents with trait \\(A\\) have payoff of \\(1+s\\). This means that trait \\(A\\) gives a payoff advantage to its bearers, relative to agents possessing trait \\(B\\). The larger is \\(s\\), the bigger this relative advantage.\n\n\nIndirectBias <- function(\n    N,     # number of agents,\n    s,     # relative advantage,\n    p_0,   # initial proportion of trait \"A\",\n    t_max  # number of generations\n  ) {\n  \n  agent <- data.frame(\n    trait = sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0))\n  ) \n\n  agent$payoff[agent$trait == \"A\"] <- 1 + s\n  agent$payoff[agent$trait == \"B\"] <- 1\n  \n  agent_list <- purrr::accumulate(\n    .x = 2:t_max, \n    .init = agent, \n    .f = function(agent, ...) {\n      \n      previous_agent <- agent ## copy agent to previous_agent dataframe\n      relative_payoffs <- agent$payoff / sum(agent$payoff) ## get relative payoffs\n      \n      agent$trait <- sample(\n        x = previous_agent$trait, \n        size = N, \n        replace = TRUE, \n        prob = relative_payoffs\n      )\n      \n      ## add payoffs\n      agent$payoff[agent$trait == \"A\"] <- 1 + s\n      agent$payoff[agent$trait == \"B\"] <- 1\n \n      return(agent)\n  })\n  \n  p <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait == \"A\") / N)\n  return(p)\n  \n}\n\n\nout <- rerun_parallel(S = 300, IndirectBias, N = 10000, s = 0.1, p_0 = 0.01, t_max = 150)\nplotSimulation(out)\n\n\n\n\nThis S-shaped curve is very similar to the one generated in Chapter 4 for direct bias. This shouldn’t be surprising given that “an agent’s payoff is entirely determined by their cultural trait. Under these assumptions, preferentially copying high payoff agents is functionally equivalent to preferentially copying high payoff traits.”\nThis is not always the case."
  },
  {
    "objectID": "transmission_bias2.html#hitch-hiking",
    "href": "transmission_bias2.html#hitch-hiking",
    "title": "5  Biased Transmission 2",
    "section": "5.2 Hitch-hiking",
    "text": "5.2 Hitch-hiking\n\nA more interesting case of indirect bias occurs when individuals possess two cultural traits, one functional and the other neutral. Under certain circumstances, payoff based indirect bias can cause the neutral trait to ‘hitch-hike’ alongside the functional trait. Neutral traits can spread in the population simply because they are associated with high payoff traits in high payoff demonstrators, even though they have no effect on payoffs themselves.\n\nIn the previous model, trait \\(A\\) is functional in that it has a higher payoff than \\(B\\) when \\(s \\gt 0\\). A neutral trait, on the other hand, has no effect on payoffs, much like the traits in Chapter 2 (unbiased transmission).\nHere, we will add a second neutral trait to IndirectBias(), which we label \\(X\\) or \\(Y\\). We also define \\(q\\) as the proportion of \\(X\\) in trait 2.\n\nWe will model a situation where the two traits may be initially linked. We are not going to be concerned here with why the two traits are initially linked. The link could, for example, have arisen by chance due to drift in historically small populations. We will leave this as an assumption of our model, which is fine as long as we are explicit about this.\n\n\\(L\\) specifies the probability that, in the starting generation, if an individual has \\(A\\) for trait 1 it also has \\(X\\) for trait 2. When \\(L = 1\\), there is a maximum linkage between the two traits—i.e., all individuals with \\(A\\) also have \\(X\\). As \\(L\\) gets smaller, this linkage breaks.\nIn sum, the demonstrators are picked as before (based on relative payoffs), except that trait 2 is copied from the same demonstrator alongside trait 1.\nNote. There’s also a new parameter \\(q_0\\) which looks a lot like \\(p_0\\) but is conditional on \\(L\\).\n\nIndirectBias2 <- function(\n    N,     # number of agents,\n    s,     # relative advantage,\n    L,     # probability that specifies linkage between \"A\" and \"X\",\n    p_0,   # initial proportion of trait \"A\",\n    q_0,   # initial proportion \n    t_max  # number of generations\n  ) {\n  \n  agent <- data.frame(\n    trait1 = sample(c(\"A\", \"B\"), size = N, replace = TRUE, prob = c(p_0, 1-p_0)),\n    trait2 = rep(NA_character_, N)\n  ) \n  \n  # with prob L, trait 2 is tied to trait 1\n  prob <- runif(N)\n  agent$trait2[agent$trait1 == \"A\" & prob < L] <- \"X\"\n  agent$trait2[agent$trait1 == \"B\" & prob < L] <- \"Y\"\n  \n  # otherwise trait \"X\" with prob q_0 (and \"Y\" with 1 - q_0)\n  agent$trait2[prob >= L] <- sample(\n    x = c(\"X\",\"Y\"), \n    size = sum(prob >= L), \n    replace = TRUE,\n    prob = c(q_0, 1-q_0)\n  )\n    \n  agent$payoff[agent$trait1 == \"A\"] <- 1 + s\n  agent$payoff[agent$trait1 == \"B\"] <- 1\n  \n  agent_list <- purrr::accumulate(\n    .x = 2:t_max, \n    .init = agent, \n    .f = function(agent, ...) {\n      \n      previous_agent <- agent ## copy agent to previous_agent dataframe\n      relative_payoffs <- agent$payoff / sum(agent$payoff) ## get relative payoffs\n      \n      # new traits copied from previous generation, biased by payoffs\n      demonstrators <- sample(1:N, size = N, replace = TRUE, prob = relative_payoffs)\n      \n      agent$trait1 <- previous_agent$trait1[demonstrators]\n      agent$trait2 <- previous_agent$trait2[demonstrators]\n      \n      ## add payoffs\n      agent$payoff[agent$trait1 == \"A\"] <- 1 + s\n      agent$payoff[agent$trait1 == \"B\"] <- 1\n \n      return(agent)\n  })\n  \n  p <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait1 == \"A\") / N)\n  q <- purrr::map_dbl(agent_list, function(agent) sum(agent$trait2 == \"X\") / N)\n  \n  data.frame(p, q)\n  \n}\n\n\nThis presents a coding challenge since the previous helper functions expect the simulation to have 1 vector as an output, but this simulation outputs p and q.\n\n\nout <- IndirectBias2(\n  N = 10000, \n  s = 0.1,\n  L = 0.9,\n  p_0 = 0.01,\n  q_0 = 0.5,\n  t_max = 150\n)\n\n\nout |> \n  rowid_to_column(\"generation\") |> \n  pivot_longer(!generation) |> \n  ggplot(aes(generation, value, color = name)) + \n  geom_line()\n\n\n\n\nHOW DO I INTEGRATE THIS WITH THE HELPER FUNCTIONS??"
  },
  {
    "objectID": "probability_puzzles.html",
    "href": "probability_puzzles.html",
    "title": "Probability Puzzles",
    "section": "",
    "text": "Some remarks about probability puzzles"
  },
  {
    "objectID": "fivethirtyeight.html",
    "href": "fivethirtyeight.html",
    "title": "6  FiveThirtyEight",
    "section": "",
    "text": "This is my first simulation notebook, inspired by David Robinson’s youtube screencast.\nHopefully this will become a regular exercise for me.\nSource:"
  },
  {
    "objectID": "fivethirtyeight.html#riddler-express",
    "href": "fivethirtyeight.html#riddler-express",
    "title": "6  FiveThirtyEight",
    "section": "6.1 Riddler Express",
    "text": "6.1 Riddler Express\n\nThese days I always have a pack of latex gloves nearby. But it’s notoriously difficult to pull exactly two gloves out of the box at a time. Sometimes I’ll pull out two gloves, other times three, and yet other times four. Somehow, I never pull out any other number of gloves at a time.\nThis morning, I noticed that there are 10 gloves left in the box. How many distinct ways are there for me to remove all 10 gloves from the box? Note that the order matters here — for example, pulling out two gloves, then four gloves and then another four gloves is distinct from pulling out four gloves, another four gloves and then two gloves.\n\nThis is a counting exercise.\nBasically, we are finding sequences of 2, 3, and 4s that add up to 10.\nPen and paper:\n\n\\(\\{2, 2, 2, 2, 2\\} \\times 1\\)\n\\(\\{4, 2, 2, 2\\} \\times 4\\)\n\\(\\{4, 4, 2\\} \\times 3\\)\n\\(\\{3, 3, 4\\} \\times 3\\)\n\\(\\{3, 3, 2, 2\\} \\times 5\\)\n\nTotal: \\(1 + 3 + 3 + 4 + 5 = 16\\)"
  },
  {
    "objectID": "fivethirtyeight.html#riddler-classic",
    "href": "fivethirtyeight.html#riddler-classic",
    "title": "6  FiveThirtyEight",
    "section": "6.2 Riddler Classic",
    "text": "6.2 Riddler Classic\n\nFrom Chris Nho comes a question of rolling (and re-rolling) a die:\nYou start with a fair 6-sided die and roll it six times, recording the results of each roll. You then write these numbers on the six faces of another, unlabeled fair die. For example, if your six rolls were 3, 5, 3, 6, 1 and 2, then your second die wouldn’t have a 4 on it; instead, it would have two 3s.\nNext, you roll this second die six times. You take those six numbers and write them on the faces of yet another fair die, and you continue this process of generating a new die from the previous one.\nEventually, you’ll have a die with the same number on all six faces. What is the average number of rolls it will take to reach this state?\nExtra credit: Instead of a standard 6-sided die, suppose you have an N-sided die, whose sides are numbered from 1 to N. What is the average number of rolls it would take until all N sides show the same number?\n\n\n# https://fivethirtyeight.com/features/can-you-get-the-gloves-out-of-the-box/\n\ndie <- 1:6\n\ndie <- sample(die, replace = TRUE)\ndie <- sample(die, replace = TRUE)\ndie <- sample(die, replace = TRUE)\n## etc.\ndie\n\n[1] 4 5 5 5 4 5\n\ndie <- 1:6\nn <- 0\nwhile (length(unique(die)) > 1) {\n  die <- sample(die, replace = TRUE)\n  n <- n + 1\n}\ndie\n\n[1] 4 4 4 4 4 4\n\nn\n\n[1] 6\n\nsimulation <- function(num_sides = 6) {\n  die <- 1:num_sides\n  n <- 0\n  while (length(unique(die)) > 1) {\n    die <- sample(die, replace = TRUE)\n    n <- n + 1\n  }\n  return(n)\n}\n\nresult <- replicate(1e4, simulation())\nmean(result)\n\n[1] 9.6289\n\nhist(result)\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n\nresult <- map_dbl(1:1e4, ~ simulation())\nmean(result)\n\n[1] 9.6573\n\naccumulate(1:10, ~ sample(., replace = TRUE), .init = 1:6)\n\n[[1]]\n[1] 1 2 3 4 5 6\n\n[[2]]\n[1] 6 6 3 2 3 1\n\n[[3]]\n[1] 6 2 1 2 6 2\n\n[[4]]\n[1] 1 2 1 1 1 2\n\n[[5]]\n[1] 1 1 1 1 1 2\n\n[[6]]\n[1] 1 1 1 1 1 1\n\n[[7]]\n[1] 1 1 1 1 1 1\n\n[[8]]\n[1] 1 1 1 1 1 1\n\n[[9]]\n[1] 1 1 1 1 1 1\n\n[[10]]\n[1] 1 1 1 1 1 1\n\n[[11]]\n[1] 1 1 1 1 1 1\n\nsimulate_with_purrr <- function(num_sides = 6) {\n  rolls <- accumulate(1:1e3, function(x, ...) {\n    die <- sample(x, replace = TRUE) \n  \n      if (length(unique(die)) == 1) {\n        done(die)\n      } else {\n        die\n      }\n    }, .init = 1:num_sides)\n  return(length(rolls) - 1)\n}\n\nresult <- replicate(100, simulate_with_purrr(50))\n\nresult\n\n  [1]  33  77 154 111  86 105  60  84  48 134 238  54  30 104  49 153 119  53\n [19]  51  68  96 126  48 341 108  64  60  56  64 208 100 172  44  57  53  81\n [37] 103  75  29 202  65 138  72  50  98  91  66  68  57  80  76  42 204  80\n [55] 113 181 171 126 114 191  53 112 109 114  32 169  45  76  75 139  89 128\n [73]  82  90 140 121  79 110  34  52  83  97 115 161  80  62  59  75 173  60\n [91]  88  57  94  92  71 136 117  82 113  56\n\ndf <- crossing(num_sides = 1:10, trial = 1:1000) %>% \n  mutate(sim = map_dbl(num_sides, simulate_with_purrr))\ndf\n\n# A tibble: 10,000 × 3\n   num_sides trial   sim\n       <int> <int> <dbl>\n 1         1     1     1\n 2         1     2     1\n 3         1     3     1\n 4         1     4     1\n 5         1     5     1\n 6         1     6     1\n 7         1     7     1\n 8         1     8     1\n 9         1     9     1\n10         1    10     1\n# … with 9,990 more rows\n\ndf %>% \n  group_by(num_sides) %>% \n  summarize(avg = mean(sim)) %>% \n  ggplot(aes(num_sides, avg)) + \n  geom_point() + \n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\ndf_avg <- df %>% \n  group_by(num_sides) %>% \n  summarize(avg = mean(sim))\n\nlm(avg ~ num_sides, data = df_avg %>% filter(num_sides > 1))\n\n\nCall:\nlm(formula = avg ~ num_sides, data = df_avg %>% filter(num_sides > \n    1))\n\nCoefficients:\n(Intercept)    num_sides  \n     -1.806        1.933  \n\ndf %>% \n  ggplot(aes(x = sim)) + \n  geom_histogram(binwidth = 1) + \n  facet_wrap(~ num_sides, scales = \"free_y\")"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Henrich, Joseph. 2001. “Cultural Transmission and the Diffusion of\nInnovations: Adoption Dynamics Indicate That Biased Cultural\nTransmission Is the Predominate Force in Behavioral Change.”\nAmerican Anthropologist 103 (4): 9921013."
  }
]